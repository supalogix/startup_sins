\subsection{Newton’s Fluxions: Good for Motion, Bad for Literally Everything Else}  

By the time \textbf{Leonhard Euler} came onto the scene, the calculus community was at war. The Newtonians and the Leibnizians weren’t just debating notation—they were waging an \textbf{intellectual blood feud}.  

Each side was convinced that their approach was \textbf{the} correct one. Newton’s camp insisted that calculus should be all about \textbf{fluxions}—because, apparently, describing motion in terms of mystical "flowing quantities" made perfect sense. Meanwhile, Leibniz’s followers swore by \textbf{infinitesimals}, because why not treat change as a weird fraction of an infinitely small number?  

This wasn’t just an argument—it was a full-blown academic street fight. Mathematicians picked sides. The British stuck with Newton. The Continental Europeans rallied behind Leibniz. Papers were written. Insults were exchanged. Careers were ruined. \textbf{Nobody was solving real problems anymore—they were too busy dunking on each other.}  

And then came \textbf{Euler}, who took one look at both sides and basically said:  

\begin{quote}
    \textbf{"You're both wrong. Your notation is terrible. I'm fixing it."}
\end{quote}  

Newton’s approach was great—if you were only ever solving physics problems. He thought of \textbf{fluxions} as rates of change over time, writing them as:

\[
\dot{x}, \quad \ddot{x}, \quad \sum o
\]

The problem?  

\begin{itemize}
    \item The dot notation was fine for \textbf{velocity and acceleration}, but completely fell apart when applied to anything outside of physics.
    \item It didn’t extend well to \textbf{functions of multiple variables} (good luck differentiating anything with two inputs).
    \item If you wanted higher derivatives, you were stuck stacking dots like some kind of deranged Morse code.  
\end{itemize}
