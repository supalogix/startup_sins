\section{Tarski in the Loop: Truth Beyond Proof}

If Lorenzen grounded mathematics in the acts of proving, then \textbf{Alfred Tarski} grounded it in the idea of truth itself—not as a human operation, but as a relation between language and a structure.

Where Lorenzen asked, \emph{“What can you build?”}, Tarski asked:

\begin{quote}
    “What does it mean for a statement to be true?”
\end{quote}

His answer became the foundation of modern \textbf{model theory}:  
truth is defined not by provability inside a system, but by satisfaction in a model.

In his seminal 1933 paper on the semantic conception of truth, Tarski gave formal precision to an ancient idea: a statement is true if it corresponds to reality. Except in mathematics, “reality” isn’t the physical world—it’s a \emph{model}: a structure where symbols get interpreted and evaluated.

\textbf{Proof theory} studies what can be derived from axioms.  
\textbf{Model theory} studies what’s true in models.

\begin{center}
    \textit{Not what you can prove, but what holds under interpretation.}
\end{center}

\vspace{1em}

\subsection{From Models to Meaning}

For Tarski, meaning wasn’t tied to human operations, but to the relationship between language and structure. A predicate gains meaning by its interpretation in a model. A theory gains content by the class of models where its axioms hold.

Where Lorenzen’s constructivism kept mathematics close to human procedure, Tarski’s semantics took mathematics outward—into an abstract space of possible models.

This shift wasn’t just technical. It marked a philosophical divide:

\begin{itemize}
  \item Lorenzen’s world: mathematics as human-constructive activity.
  \item Tarski’s world: mathematics as a landscape of structures where truth is evaluated.
\end{itemize}

And while Lorenzen distrusted abstraction, Tarski formalized it: his definition of truth empowered mathematicians to reason about statements \emph{across models}, even when no construction or proof was possible inside a particular system.

\vspace{1em}

\subsection{Model Theory Meets Machine Learning}

At first glance, Tarski’s project seems even further removed from modern machine learning than Lorenzen’s. But model theory’s fingerprints are all over the AI and ML landscape—especially wherever symbols, structures, and semantics collide.

\textbf{1. Knowledge representation:}  
Model theory underlies the semantics of \textbf{logic programming}, \textbf{knowledge graphs}, and \textbf{ontology languages} like OWL and RDF. In AI systems that must reason over symbolic knowledge bases, Tarskian semantics defines what counts as a valid inference in a given interpretation.

\textbf{2. Formal semantics in NLP:}  
In natural language processing, attempts to map sentences to logical forms depend on model-theoretic semantics to specify what those forms mean across possible worlds.

\textbf{3. Neuro-symbolic systems:}  
The emerging field of \textbf{neurosymbolic AI}—which seeks to blend neural networks with symbolic reasoning—often relies on model-theoretic logic to define how neural representations can interact with symbolic constraints.

\textbf{4. Database query languages:}  
SQL, Datalog, and other query languages are deeply tied to model-theoretic semantics: a query is true if it holds in the model defined by the database instance.

\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=\textbf{Sidebar: Why Model Theory Matters for ML}, fonttitle=\bfseries, arc=1.5mm, boxrule=0.4pt]
\textbf{Model theory:} The study of logical structures and what’s true in them.

\textbf{In machine learning:}
\begin{itemize}
  \item Defines semantics for symbolic reasoning modules in neuro-symbolic systems.
  \item Underlies knowledge representation in AI.
  \item Provides formal grounding for logical constraints in hybrid models.
  \item Informs formal semantics in natural language understanding.
\end{itemize}

It’s not about training weights—it’s about keeping symbols meaningful.
\end{tcolorbox}

\vspace{1em}

\subsection{The Semantic Mirror of Learning}

While proof theory builds meaning from derivability, model theory builds meaning from interpretation. In an era where machine learning systems increasingly blur the line between pattern recognition and symbolic manipulation, the contrast between these perspectives grows sharper—and more necessary.

For every neural network predicting outputs, there’s a rising demand for models that don’t just correlate, but \emph{explain}—that respect logical constraints, satisfy symbolic rules, or operate within a structured knowledge base.

In this context, Tarski’s work remains a quiet foundation: the semantic mirror that lets us ask, \emph{“What does this symbol mean in this system?”}, and \emph{“In which worlds is this sentence true?”}

\begin{quote}
    “A model is a world. Model theory lets us ask: in which worlds does the machine make sense?”
\end{quote}
