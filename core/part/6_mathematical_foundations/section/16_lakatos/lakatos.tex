\section{Lakatos in the Loop: How Science Lives Without Foundations}

If Carnap turned truth into a configuration setting, then \textbf{Imre Lakatos} made the whole process dynamic. He took one look at rigid formal systems and said: that‚Äôs not how discovery works.

Lakatos wasn‚Äôt interested in the logic of a single airtight proof. He wanted to understand \textit{how we move through ideas}, especially when they fail. His philosophy of science is messy, iterative, and suspiciously familiar to anyone who's ever trained a neural network.

Instead of looking for fixed foundations, Lakatos studied how theories evolve over time‚Äîthrough tensions, adjustments, and conceptual patchwork. His key insight was that real science doesn‚Äôt abandon a theory the moment it stumbles. It adapts. It makes excuses. It reroutes blame. And sometimes, it stumbles into something better.

\begin{quote}
    \textit{‚ÄúTheories are not abandoned when refuted; they are abandoned when they stop being useful.‚Äù}
\end{quote}

He called this process a \textbf{research programme}: a living system of ideas, with a hard core of principles surrounded by a flexible belt of auxiliary assumptions. It‚Äôs not unlike how we treat machine learning models today:

\begin{itemize}
  \item The model architecture is sacred (for now).
  \item The hyperparameters are negotiable.
  \item If it doesn‚Äôt work? Tweak the belt, not the core.
\end{itemize}

In Lakatos‚Äôs world, truth is not a fixed point. It‚Äôs a direction. A good theory is one that leads somewhere‚Äîpredicts novel results, opens new paths, survives criticism. A bad theory is one that only survives by dodging it.

\vspace{1em}

\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=\textbf{Sidebar: Machine Learning as a Lakatosian Ritual}, fonttitle=\bfseries, arc=1.5mm, boxrule=0.4pt]
What is training, if not a form of iterative research?

\textbf{Hard core:} The model class (transformers, CNNs, decision trees).  
\textbf{Protective belt:} Learning rate schedules, batch sizes, optimizer tricks, data augmentations.

We don‚Äôt discard deep learning every time it overfits. We modify the belt. We publish a paper. We call it ‚Äústate-of-the-art.‚Äù

\medskip

\textbf{Falsification?} Not really.  
\textbf{Progressive research programme?} If it predicts new benchmarks, yes.

\end{tcolorbox}

\vspace{1em}

In this light, Carnap and Lakatos make an unlikely but compelling duo. One gave us the freedom to define truth within systems. The other gave us a philosophy for evolving systems over time. Together, they describe the actual life of mathematical and scientific thought:

\begin{quote}
    Not the quest for a single truth,  
    but the dance between structure and surprise.
\end{quote}

\subsection{Lakatos Meets the GPU: The Hard Core and the Belt}

In Lakatos‚Äôs model of science, theories aren‚Äôt judged in isolation. Each one comes bundled with a structure: a \textbf{hard core} of central assumptions, surrounded by a \textbf{protective belt} of auxiliary hypotheses and patches.

\begin{itemize}
  \item The hard core is sacred‚Äîit defines the identity of the theory.
  \item The protective belt is negotiable‚Äîit takes the hits, absorbs the failures, and gets quietly revised.
\end{itemize}

This isn‚Äôt just a philosophy of science. It‚Äôs a debug log for machine learning.

\textbf{Hard core:} The model class. Transformers. CNNs. Diffusion models. Whatever miracle architecture we‚Äôre pretending to understand this year.

\textbf{Protective belt:} Everything we‚Äôre willing to fiddle with:
\begin{itemize}
  \item learning rates
  \item optimizers
  \item regularization schedules
  \item dropout patterns
  \item weight initializations
  \item batch sizes
  \item data augmentation rituals
\end{itemize}

And when a model fails? We don‚Äôt throw out deep learning.  
We don‚Äôt say, ‚ÄúPerhaps neural networks were a mistake.‚Äù

We say:
\begin{quote}
    ‚ÄúTry AdamW instead of SGD. Warm up the learning rate. Freeze the first ten layers. Add a cosine scheduler. Did you normalize your inputs?‚Äù
\end{quote}

\textbf{The hard core survives. The belt gets updated.}

In Lakatosian terms, this is exactly how robust research programmes behave. They protect their central commitments while constantly adjusting their outer shell. And if those adjustments lead to \textit{novel performance}‚Äîa new benchmark, a new task‚Äîthen the programme is \textbf{progressive}.

If not? Degenerative.

\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=\textbf{Sidebar: The Lakatosian Debugger}, fonttitle=\bfseries, arc=1.5mm, boxrule=0.4pt]
\textbf{Is deep learning falsifiable?}  
Not really.

\textbf{Is it scientific in Lakatos‚Äôs sense?}  
Absolutely‚Äîbecause it behaves like a research programme:
\begin{itemize}
  \item It adapts to survive critique.
  \item It predicts new results.
  \item It doesn‚Äôt die when it fails‚Äîit mutates.
\end{itemize}

\textbf{Progressive?} Yes‚Äîfor now.

\textbf{Degenerative?} Ask again after the next paper drop.
\end{tcolorbox}

\subsection{Progress or Patchwork? ML Through Lakatos‚Äôs Telescope}

Lakatos drew a sharp line between two types of scientific activity:

\begin{itemize}
  \item \textbf{Progressive research programmes} generate novel predictions, explain new phenomena, and open doors to previously unseen problems.
  \item \textbf{Degenerative research programmes} survive mainly by retrofitting explanations to known results, spinning their wheels in increasingly elaborate justifications that lead nowhere new.
\end{itemize}

In other words: Are you doing science, or are you just very good at excuses?

Machine learning lives on both sides of this divide.

\bigskip

\textbf{Progressive ML:}  
When a research programme predicts something unexpected‚Äîmultimodal reasoning, in-context learning, emergent capabilities‚Äîit earns its keep. GPT-2 led to GPT-3, which led to GPT-4, which led to people asking if language models have theory of mind. That‚Äôs not just curve fitting. That‚Äôs exploration.

\bigskip

\textbf{Degenerative ML:}  
Leaderboard chasing. Test set overfitting. Publishing a whole paper because you adjusted the dropout rate and saw a 0.003% improvement on a dataset whose labels were crowd-sourced by sleepy undergrads.

\begin{quote}
    ‚ÄúWe improve the baseline by a statistically significant margin.‚Äù\\
    ‚Äî The academic equivalent of rearranging deck chairs on the Titanic.
\end{quote}

The problem isn‚Äôt optimization. It‚Äôs \textit{strategic stagnation}‚Äîthe point where a field is no longer asking new questions, just gaming old ones.

\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=\textbf{Sidebar: How to Spot Degeneracy}, fonttitle=\bfseries, arc=1.5mm, boxrule=0.4pt]
\vspace{-0.5em}
\begin{itemize}
  \item New paper, same dataset? ‚ö†Ô∏è
  \item Novel metric, but no insight? ‚ö†Ô∏è
  \item Private test set, secret sauce, no code? üö®
  \item Model ‚Äúimproves SOTA‚Äù but fails in real-world deployment? üö®
\end{itemize}

\textbf{Lakatos didn‚Äôt say this, but he would‚Äôve:}  
‚ÄúThe moment a field starts using custom data splits and private test sets, it‚Äôs probably sliding into degeneracy.‚Äù
\end{tcolorbox}

\bigskip

Lakatos reminds us that scientific progress isn‚Äôt about small numerical deltas‚Äîit‚Äôs about \textit{conceptual mobility}. The ability to explain more, predict more, and rethink what a system is even for.

Machine learning, at its best, is a progressive programme.  
At its worst, it‚Äôs a spreadsheet arms race.


\subsection{Quasi-Empirical Everything: Deep Learning as Experimental Math}

In his groundbreaking work \textit{Proofs and Refutations}, Lakatos argued that mathematics doesn‚Äôt grow out of pure, sterile deduction. It grows like science: through counterexamples, failed conjectures, and conceptual repairs. Proofs aren‚Äôt endpoints‚Äîthey‚Äôre conversational moves in a larger game of refinement.

This wasn‚Äôt just a critique of formalism. It was a philosophy of mathematical discovery as \textbf{quasi-empirical}.

Which makes Lakatos sound suspiciously like a deep learning researcher with too many GPUs and not enough theory.

\bigskip

Modern deep learning doesn‚Äôt proceed from first principles. It moves the way Lakatos described mathematics evolving:

\begin{itemize}
  \item We don‚Äôt prove generalization bounds. We watch them fail on CIFAR.
  \item We don‚Äôt derive performance guarantees. We try weird tricks and hope they work.
  \item We don‚Äôt start with the axioms. We start with a Jupyter notebook, a pretrained model, and a vague sense of dread.
\end{itemize}

The epistemology of deep learning is unapologetically experimental. We get results first, then try to justify them. If anything, our proofs are often \textit{post hoc alibis}‚Äîwritten long after the fact to explain why something already works.

\begin{quote}
    ‚ÄúThis trick increases performance by 4.3%. We don‚Äôt know why, but we named it something Greek and published a paper.‚Äù
\end{quote}

\bigskip

\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=\textbf{Sidebar: Empirical Until Proven Otherwise}, fonttitle=\bfseries, arc=1.5mm, boxrule=0.4pt]
\textbf{Lakatos:} Mathematics progresses through refutations and repairs.  
\textbf{Deep Learning:} We progress through ablation studies and vibes.

\medskip

Ablate a component. Try a different schedule. Swap GELU for SiLU. Publish the best configuration.  
Later, maybe, someone will figure out \textit{why} it worked.

\medskip

This isn‚Äôt bad science‚Äîit‚Äôs Lakatosian science.  
\textit{Fallible, iterative, and creative.}
\end{tcolorbox}

\bigskip

Lakatos saw mathematical discovery as a process of evolution‚Äînot of eternal truths, but of increasingly useful structures. Deep learning isn‚Äôt built on formalism. It‚Äôs built on experiments, intuitions, and accidental breakthroughs. It doesn‚Äôt aim for proof. It aims for performance.

It is, in every meaningful sense, \textbf{quasi-empirical mathematics with a CUDA backend}.


\subsection{Falsification Is Fuzzy: The ML Problem Lakatos Saw Coming}

Popper gave us a crisp rule: science advances by bold conjectures and ruthless refutations. A theory makes a prediction. The prediction fails. The theory dies.

Clean. Sharp. Satisfying.

And also, almost never what actually happens‚Äîespecially not in machine learning.

\bigskip

Lakatos took issue with this neatness. He pointed out that scientific theories aren‚Äôt tested in isolation. They come wrapped in assumptions, measurement methods, background models, and auxiliary code nobody has touched since 2017. So when something breaks, you don‚Äôt actually know what failed.

Machine learning is the poster child for this problem.

\bigskip

\textbf{Did the model fail?}  
Or was the dataset mislabeled?  
Or the labels biased?  
Or the optimizer unstable?  
Or the random seed cursed?

\bigskip

\textbf{In ML, falsification is never clean.}  
It‚Äôs distributed across a pipeline.

And just like Lakatos warned, we rarely throw out the core model. We question the preprocessing. We rerun with a different initialization. We file a GitHub issue and reframe the failure as a "known limitation."

\begin{quote}
    ‚ÄúThe model underperforms on this benchmark, possibly due to domain shift.‚Äù  
    ‚Äî Translation: We don‚Äôt actually know what went wrong, but we‚Äôre not scrapping the architecture.
\end{quote}

\bigskip

\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=\textbf{Sidebar: Popperian Falsification vs. ML Reality}, fonttitle=\bfseries, arc=1.5mm, boxrule=0.4pt]
\textbf{Popper:} A single failed prediction refutes the theory.  
\textbf{Lakatos:} Not so fast. Was it the theory‚Äîor the auxiliary belt?

\textbf{ML:} The loss went up. Quick‚Äîblame the learning rate.

\medskip

Modern ML embodies Lakatos‚Äôs insight:  
You don‚Äôt refute a model.  
You negotiate with it.
\end{tcolorbox}

\bigskip

In this view, machine learning isn‚Äôt falsifiable in the traditional Popperian sense‚Äînot because it‚Äôs unscientific, but because it‚Äôs too complex. Its truth claims are embedded in layers of interaction, not logical propositions.

For Lakatos, that wasn‚Äôt a bug. It was the reality of scientific progress.

\begin{quote}
    Not a clean break with error‚Äî  
    but an ongoing conversation with uncertainty.
\end{quote}


\subsection{ML as a Battlefield of Research Programmes}

Lakatos saw science as a series of competing research programmes‚Äîeach with its own central commitments (the \textbf{hard core}) and an adjustable perimeter of hacks, patches, and strategic retreats (the \textbf{protective belt}). 

Machine learning is no exception. It‚Äôs not one programme‚Äîit‚Äôs a colosseum of them, all battling for relevance, funding, and arXiv clout.

\bigskip

Let‚Äôs take a Lakatosian tour of the main contenders:

\paragraph{Deep Learning}  
The reigning champion. Its hard core is the twin faith in \textbf{universal approximation} and \textbf{backpropagation}. Everything else‚Äîattention mechanisms, dropout, weight decay, bizarre positional encodings‚Äîis part of the protective belt. 

If something fails? The optimizer gets tweaked. The loss gets custom-shaped. The core survives.

\textbf{Status:} \textit{Progressive (for now)}. It keeps producing new capabilities and weirdly coherent text.

\paragraph{Symbolic AI (GOFAI)}  
The OG programme: logic, rule systems, and explicit knowledge graphs. It reigned from the 1950s to the early 80s, when it collapsed under its own brittleness and failure to scale.

\textbf{Status:} \textit{Degenerative}. It now survives mainly in PowerPoints about "hybrid approaches" and intro CS textbooks.

\paragraph{Bayesian Machine Learning}  
Founded on probabilistic reasoning and the idea of modeling uncertainty explicitly. Its protective belt includes variational inference, MCMC tricks, and enough Greek letters to summon Laplace himself.

\textbf{Status:} \textit{Still hanging on}. Popular in theory-heavy circles and certain corners of reinforcement learning. Slowly being rebranded as ‚Äúprobabilistic programming.‚Äù

\paragraph{Neurosymbolic ML}  
The hopeful middle child. It wants to combine the pattern-matching power of deep learning with the structure and interpretability of symbolic reasoning. Its belt includes graph modules, compositional architectures, and a lot of yearning.

\textbf{Status:} \textit{Emerging}. The press loves it. The codebase is... still under construction.

\bigskip

\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=\textbf{Sidebar: ML Research Programmes in Lakatosian Terms}, fonttitle=\bfseries, arc=1.5mm, boxrule=0.4pt]
\begin{tabular}{|p{3.5cm}|p{4cm}|p{5.5cm}|p{3cm}|}
\hline
\textbf{Programme} & \textbf{Hard Core} & \textbf{Protective Belt} & \textbf{Status} \\
\hline
Deep Learning & Universal approximation, backpropagation & Attention, dropout, optimizer tweaks & \textit{Progressive (for now)} \\
\hline
Symbolic AI (GOFAI) & Logic rules, explicit knowledge & Constraint tweaking & \textit{Degenerative} \\
\hline
Bayesian ML & Probabilistic reasoning, priors & Approximate inference, variational methods & \textit{Still hanging on} \\
\hline
Neurosymbolic ML & Hybrid reasoning & Graph modules, interpretable layers & \textit{Emerging} \\
\hline
\end{tabular}
\end{tcolorbox}

\bigskip

Each programme is a bet on a certain vision of intelligence. And just like Lakatos predicted, we don‚Äôt always switch to the most rational theory‚Äîwe follow the one that still leads somewhere interesting.

\begin{quote}
In ML, as in science: theories don‚Äôt die.  
They fade into GitHub branches nobody updates.
\end{quote}


\subsection*{Lakatos vs. Transformer: A Side-by-Side Roast}

\vspace{1em}

\begin{tcolorbox}[colback=gray!5!white, colframe=black, title=\textbf{Lakatos vs. Transformer}, fonttitle=\bfseries, arc=1.5mm, boxrule=0.4pt]

\begin{tabular}{p{6.5cm} | p{6.5cm}}
\textbf{Imre Lakatos} & \textbf{Transformer (The Model)} \\
\hline
Wrote a whole philosophy showing that theories only die when they stop being useful. & Trained on Reddit, StackOverflow, and fanfiction. Still somehow useful. \\
\hline
Believes science evolves through patchwork, not perfection. & Was patchworked into existence from a Frankenstein of residuals, attention heads, and LayerNorm. \\
\hline
Argued that falsification is messy and rarely decisive. & ‚ÄúValidation loss increased? Try a different seed. It's not dead yet.‚Äù \\
\hline
Thought the protective belt was where all the creativity happens. & Its entire architecture is basically a protective belt with delusions of grandeur. \\
\hline
Came up with the idea of research programmes to explain theory change. & Is the reason the term ‚Äúresearch programme‚Äù now means ‚Äúfine-tuning 13B parameters on llama memes.‚Äù \\
\hline
Wanted science to be rational, but fallible. & Is fallible, but somehow still deployed in production. \\
\hline
Argued that mathematical discovery is quasi-empirical. & Was discovered quasi-empirically. Then immediately turned into a unicorn startup. \\
\hline
Didn‚Äôt trust clean Popperian demarcation lines. & Routinely blurs the line between learning and memorizing‚Äîsometimes in the same epoch. \\
\hline
%Would say ‚Äútruth is provisional, context-bound, and corrigible.‚Äù & Says ‚ÄúThe mitochondria is the powerhouse of the cell‚Äù 99.7\% of the time, regardless of context. \\
%\hline
%Got into philosophical arguments about Newtonian science vs. Einsteinian revolutions. & Helped a teenager write fake Einstein quotes for an Instagram caption. \\
\end{tabular}

\end{tcolorbox}

\bigskip

\begin{quote}
\textbf{Lakatos:} ‚ÄúWe must track the evolution of theoretical frameworks across history.‚Äù

\textbf{Transformer:} ‚ÄúHere's 13 bullet points, 9 emojis, and a haiku about it.‚Äù
\end{quote}

\bigskip

At the end of the day, they‚Äôre not so different.

Both thrive in systems that evolve through trial, error, and reconfiguration.  
Both reject final truths.  
Both are suspicious of anything that looks too clean.

Only one is available on Hugging Face.


\begin{tcolorbox}[colback=blue!5!white, colframe=blue!50!black, 
  title={\textbf{Historical Sidebar: Feyerabend and Lakatos ‚Äî Frenemies of Scientific Method}}] 

If philosophy had a buddy-cop movie, \textbf{Imre Lakatos} and \textbf{Paul Feyerabend} would be the stars.

One believed in structured chaos. The other believed in chaos, full stop.

\bigskip

\textbf{Lakatos} tried to rescue rationality from the wreckage of Popperian falsification. His "research programmes" weren‚Äôt about strict rules‚Äîbut they still aimed to distinguish science from pseudoscience. For Lakatos, progress was messy but \textit{trackable}. There was method in the madness.

\textbf{Feyerabend}, meanwhile, looked at Lakatos‚Äôs careful balancing act and laughed. In \textit{Against Method}, he argued that even Lakatos‚Äôs flexible framework was too restrictive. Science, Feyerabend claimed, advanced precisely because people \textbf{ignored} method, broke rules, and borrowed ideas from wherever they pleased‚Äîsometimes from myth, magic, or pure accident.

\bigskip

Yet despite their philosophical clashes, Lakatos and Feyerabend were close friends‚Äîlocked in a decade-long debate that was part intellectual rivalry, part performance art.

They famously planned to co-author a dialogue titled \textbf{‚ÄúFor and Against Method‚Äù}, where Lakatos would defend rational reconstruction, and Feyerabend would gleefully tear it down. Sadly, Lakatos‚Äôs sudden death in 1974 ended the project.

\bigskip

Feyerabend later described Lakatos as:
\begin{quote}
    \textit{‚ÄúThe only philosopher of science who ever took me seriously‚Äîand who was fun to argue with.‚Äù}
\end{quote}

\bigskip

Their relationship wasn‚Äôt just a debate about method. It was a living example of it:
\begin{itemize}
  \item \textbf{Lakatos:} Science evolves through structured criticism and progressive problem shifts.
  \item \textbf{Feyerabend:} Science evolves because people break the structure and get lucky.
\end{itemize}

\bigskip

In the end, they both agreed on one thing:  
Popper was too optimistic about how clean science really is.

\end{tcolorbox}


\begin{tcolorbox}[colback=blue!5!white, colframe=blue!50!black, 
  title={\textbf{Historical Sidebar: Popper, Feyerabend, and G√∂del ‚Äî When Logic Meets Anarchy}}] 

\textbf{Karl Popper}, \textbf{Paul Feyerabend}, and \textbf{Kurt G√∂del} never formed a philosophical clique‚Äîbut if they had, it would‚Äôve been the most dysfunctional study group in the history of logic.

\bigskip

\textbf{Popper} believed in bold conjectures and clear demarcation: science advances by proposing risky theories and ruthlessly \textit{falsifying} them. Clean lines. Sharp cuts. No nonsense.

\textbf{Feyerabend}, Popper‚Äôs rebellious student, torched that ideal. In \textit{Against Method}, he argued that science had no universal method‚Äîjust a chaotic mix of strategies where \textbf{‚Äúanything goes‚Äù}. For Feyerabend, progress wasn‚Äôt about rules. It was about creativity, opportunism, and occasionally breaking every guideline in sight.

\bigskip

Enter \textbf{G√∂del}, who didn‚Äôt care much for scientific method debates‚Äîbut quietly shattered the dream both were dancing around.

Popper wanted clear boundaries for rational inquiry. Feyerabend wanted to blow them up. G√∂del proved, with mathematical precision, that within any sufficiently powerful system, there are truths you can‚Äôt reach by following the rules.

\bigskip

\textbf{G√∂del‚Äôs Incompleteness Theorem} was the ultimate buzzkill for formalists‚Äîand an accidental gift to Feyerabend.

\begin{itemize}
  \item For \textbf{Popper}, G√∂del was a cautionary tale: even logic itself couldn‚Äôt guarantee completeness or certainty.
  \item For \textbf{Feyerabend}, G√∂del was vindication: if formal systems are inherently limited, why pretend that rigid methods could ever capture the full scope of discovery?
\end{itemize}

\bigskip

While G√∂del stayed aloof‚Äîmore interested in Platonist truths than scientific squabbles‚Äîhis work cast a long shadow over 20th-century philosophy of science.

\textbf{Popper drew the lines. Feyerabend crossed them. G√∂del proved the map was incomplete.}

\end{tcolorbox}
